{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8C2_39dX9kl",
        "outputId": "91a6a4e9-8f7b-4d6c-ea97-3591328ea9a1"
      },
      "outputs": [],
      "source": [
        "pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrQpEKZt-nYw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "file_path = 'nasa93dataset.csv'\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb60Uq_mniEQ",
        "outputId": "8255d58f-79f0-453b-c71a-294b570f7153"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXtY-79V0FzD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_mmre(actuals, predictions):\n",
        "    actuals = np.array(actuals)\n",
        "    predictions = np.array(predictions)\n",
        "    relative_errors = np.abs((actuals - predictions) / np.where(actuals == 0, 1e-10, actuals))\n",
        "    return np.mean(relative_errors)\n",
        "\n",
        "def calculate_bmmre(actuals, all_predictions):\n",
        "    actuals = np.array(actuals)\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    relative_errors = [np.abs((actuals - pred) / np.where(actuals == 0, 1e-10, actuals)) for pred in all_predictions]\n",
        "    min_relative_errors = np.min(relative_errors, axis=0)\n",
        "    return np.mean(min_relative_errors)\n",
        "\n",
        "def pred_25(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    percentage_error = np.abs(y_true - y_pred) / y_true\n",
        "    within_25_percent = np.sum(percentage_error <= 0.25)\n",
        "\n",
        "    return within_25_percent / len(y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uwes1jud1SFA"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(actuals, predictions_list):\n",
        "    maes = []\n",
        "    pred25 = []\n",
        "    mmre = []\n",
        "\n",
        "    for predictions in predictions_list:\n",
        "        maes.append(mean_absolute_error(actuals, predictions))\n",
        "        pred25.append(pred_25(actuals, predictions))\n",
        "        mmre.append(calculate_mmre(actuals, predictions))\n",
        "\n",
        "    return maes, pred25,mmre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a43xpsfabKs-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_name = f\"{file_path}.xlsx\"\n",
        "\n",
        "pd.DataFrame().to_excel(file_name,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arUmsLCZWrty"
      },
      "outputs": [],
      "source": [
        "def save_to_excel(file_name, name, ensemble_df, individual_df):\n",
        "    max_rows = max(len(ensemble_df), len(individual_df))\n",
        "    ensemble_df = ensemble_df.reindex(range(max_rows))\n",
        "    individual_df = individual_df.reindex(range(max_rows))\n",
        "\n",
        "    separator_column = pd.Series([None] * max_rows, name=\"\")\n",
        "\n",
        "    df_combined = pd.concat([ensemble_df, separator_column, individual_df], axis=1)\n",
        "\n",
        "    with pd.ExcelWriter(file_name, mode=\"a\", engine=\"openpyxl\") as writer:\n",
        "        df_combined.to_excel(writer, sheet_name=f\"{name}\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTSnAYZxAYEj"
      },
      "outputs": [],
      "source": [
        "def display_results(ensemble_models, individual_models, ensemble_mae, ensemble_pred25,ensemble_mmre,individual_mae, individual_pred25,individual_mmre,ensemble_bmmre):\n",
        "\n",
        "    ensemble_df = pd.DataFrame({\n",
        "        \"Ensemble Models with\": ensemble_models,\n",
        "        \"MAE\": ensemble_mae,\n",
        "        \"MMRE\": ensemble_mmre,\n",
        "        \"BMMRE\": ensemble_bmmre,\n",
        "        \"PRED(25)\": ensemble_pred25\n",
        "    })\n",
        "\n",
        "    individual_df = pd.DataFrame({\n",
        "        \"Individual Model\": individual_models,\n",
        "        \"MAE\": individual_mae,\n",
        "        \"MMRE\": individual_mmre,\n",
        "        \"PRED(25)\": individual_pred25\n",
        "    })\n",
        "\n",
        "\n",
        "    print(\"Ensemble Models:\\n\")\n",
        "    print(ensemble_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\n------------------------------------------------------\")\n",
        "\n",
        "    print(\"\\nIndividual Models:\\n\")\n",
        "    print(individual_df.to_string(index=False))\n",
        "\n",
        "    return ensemble_df, individual_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkpCwxqiYTFf"
      },
      "source": [
        "**CBR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANEmZV7r_epZ"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "class CBR:\n",
        "  def __init__(self):\n",
        "    self.best_weights = None\n",
        "    self.best_k = None\n",
        "\n",
        "  def fit(self,X_train,y_train):\n",
        "    self.X = X_train\n",
        "    self.y = y_train\n",
        "    self.best_weights = np.random.rand(X_train.shape[1])\n",
        "    self.best_weights /= self.best_weights.sum()\n",
        "    self.best_k = random.randint(1, 10)\n",
        "\n",
        "  def predict_effort(self,X_train, y_train, X_test, weights, k):\n",
        "\n",
        "    weighted_X_train = X_train * weights\n",
        "    weighted_X_test = X_test * weights\n",
        "\n",
        "    distances = cdist(weighted_X_test, weighted_X_train, metric='euclidean')\n",
        "\n",
        "    predictions = []\n",
        "    for dist in distances:\n",
        "        neighbors = np.argsort(dist)[:k]\n",
        "\n",
        "        ranking_weights = [(2 ** (k - i - 1)) / (2 ** k - 1) for i in range(k)]\n",
        "        predicted_effort = sum(ranking_weights[i] * y_train[neighbors[i]] for i in range(k))\n",
        "        predictions.append(predicted_effort)\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "  def predict(self,X_test):\n",
        "    return self.predict_effort(self.X, self.y, X_test, self.best_weights, self.best_k)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YS31qZbfUlH"
      },
      "source": [
        "**COCOMO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am-mvr5EAsnL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# COCOMO base equation: Effort = a*(KLOC^b)*EAF\n",
        "class COCOMO(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.a = tf.Variable(2.94, trainable=True)  # Initial COCOMO II organic a\n",
        "        self.b = tf.Variable(1.12, trainable=True)  # Initial COCOMO II organic b\n",
        "        self.nn = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(32, activation='relu', input_shape=(14,)),\n",
        "            tf.keras.layers.Dense(1, activation='linear')\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        kloc = inputs[:, 15]  # LOC column\n",
        "        eaf = tf.reduce_prod(inputs[:, :15], axis=1)  # Product of cost drivers\n",
        "        base_effort = self.a * (kloc ** self.b) * eaf\n",
        "        correction = self.nn(inputs[:, :15])\n",
        "        return base_effort * (1 + correction)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.call(X).numpy().flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPZPP6kE7TBn"
      },
      "source": [
        "**Combined models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO3fhDvg7PIy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# For ensemble model combination rule\n",
        "def linear_combination(y1, y2, y3, weights):\n",
        "    return weights[0] * y1 + weights[1] * y2 + weights[2] * y3\n",
        "\n",
        "def median_combination(y1, y2, y3):\n",
        "    return np.median(np.stack([y1, y2, y3]), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtsltzXwAi-Y"
      },
      "outputs": [],
      "source": [
        "ensemble_models = [\"ANN\", \"KNN\", \"XGBooster\", \"SVR\"]\n",
        "individual_models = [\"CBR\", \"COCOMO\", \"ANN\", \"KNN\", \"XGBooster\", \"SVR\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTC9bUmHLWyW"
      },
      "source": [
        "**loocv - scaled- median**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dt0diGtx7Mnt"
      },
      "outputs": [],
      "source": [
        "loo = LeaveOneOut()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "combined_predictions_1=[]\n",
        "combined_predictions_2=[]\n",
        "combined_predictions_3=[]\n",
        "combined_predictions_4=[]\n",
        "\n",
        "model_1 = CBR()\n",
        "model_2 = COCOMO()\n",
        "model_3 = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, learning_rate_init=0.01, activation='relu', solver='adam', random_state=42, tol=1e-4)\n",
        "model_4 = KNeighborsRegressor(n_neighbors=5)\n",
        "model_5 = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model_6 = SVR(kernel='linear', C=100, gamma=0.1, epsilon=0.1)\n",
        "\n",
        "\n",
        "predictions1=[]\n",
        "predictions2=[]\n",
        "predictions3=[]\n",
        "predictions4=[]\n",
        "predictions5=[]\n",
        "predictions6=[]\n",
        "\n",
        "\n",
        "k = 1\n",
        "\n",
        "\n",
        "\n",
        "for train_index, test_index in loo.split(X_scaled):\n",
        "\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model_1.fit(X_train, y_train)\n",
        "    model_2.compile(optimizer='adam', loss='mae')\n",
        "    model_2.fit(X_train, y_train, epochs=500, batch_size=16)\n",
        "    model_3.fit(X_train, y_train)\n",
        "    model_4.fit(X_train, y_train)\n",
        "    model_5.fit(X_train, y_train)\n",
        "    model_6.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_1 = model_1.predict(X_test)\n",
        "    y_pred_2 = model_2.predict(X[test_index])\n",
        "    y_pred_3 = model_3.predict(X_test)\n",
        "    y_pred_4 = model_4.predict(X_test)\n",
        "    y_pred_5 = model_5.predict(X_test)\n",
        "    y_pred_6 = model_6.predict(X_test)\n",
        "\n",
        "    y_pred_combined_1 = median_combination(y_pred_1, y_pred_2, y_pred_3)\n",
        "    y_pred_combined_2 = median_combination(y_pred_1, y_pred_2, y_pred_4)\n",
        "    y_pred_combined_3 = median_combination(y_pred_1, y_pred_2, y_pred_5)\n",
        "    y_pred_combined_4 = median_combination(y_pred_1, y_pred_2, y_pred_6)\n",
        "\n",
        "    combined_predictions_1.extend(y_pred_combined_1)\n",
        "    combined_predictions_2.extend(y_pred_combined_2)\n",
        "    combined_predictions_3.extend(y_pred_combined_3)\n",
        "    combined_predictions_4.extend(y_pred_combined_4)\n",
        "\n",
        "    actuals.extend(y_test)\n",
        "\n",
        "    predictions1.extend(y_pred_1)\n",
        "    predictions2.extend(y_pred_2)\n",
        "    predictions3.extend(y_pred_3)\n",
        "    predictions4.extend(y_pred_4)\n",
        "    predictions5.extend(y_pred_5)\n",
        "    predictions6.extend(y_pred_6)\n",
        "\n",
        "    k = k + 1\n",
        "\n",
        "print(f\"Execution time: {execution_time} seconds\")\n",
        "ensemble_predictions = [combined_predictions_1, combined_predictions_2, combined_predictions_3, combined_predictions_4]\n",
        "individual_predictions = [predictions1, predictions2, predictions3, predictions4, predictions5, predictions6]\n",
        "\n",
        "ensemble_mae, ensemble_pred25, ensemble_mmre = calculate_metrics(actuals, ensemble_predictions)\n",
        "individual_mae, individual_pred25, individual_mmre = calculate_metrics(actuals, individual_predictions)\n",
        "\n",
        "bmmre = []\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions3]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions4]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions5]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions6]))\n",
        "\n",
        "ensemble_df, individual_df = display_results(ensemble_models, individual_models, ensemble_mae, ensemble_pred25, ensemble_mmre,individual_mae, individual_pred25,individual_mmre,bmmre)\n",
        "\n",
        "\n",
        "save_to_excel(file_name, \"loocv-scaled-median\", ensemble_df, individual_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW1E8QVE-P43"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5FzWsT54Bjn"
      },
      "outputs": [],
      "source": [
        "ensemble_predictions = [combined_predictions_1, combined_predictions_2, combined_predictions_3, combined_predictions_4]\n",
        "individual_predictions = [predictions1, predictions2, predictions3, predictions4, predictions5, predictions6]\n",
        "\n",
        "ensemble_mae, ensemble_pred25 = calculate_metrics(actuals, ensemble_predictions)\n",
        "individual_mae, individual_pred25 = calculate_metrics(actuals, individual_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPuuc5JlXAI8"
      },
      "source": [
        "**loocv - unscaled - median**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud4yOCriW4BS",
        "outputId": "1e8f9651-ab89-4fc0-cc05-4cedd571474b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "loocv=LeaveOneOut()\n",
        "\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "combined_predictions_1=[]\n",
        "combined_predictions_2=[]\n",
        "combined_predictions_3=[]\n",
        "combined_predictions_4=[]\n",
        "\n",
        "model_1 = CBR()\n",
        "model_2 = COCOMO()\n",
        "model_3 = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, learning_rate_init=0.01, activation='relu', solver='adam', random_state=42)\n",
        "model_4 = KNeighborsRegressor(n_neighbors=5)\n",
        "model_5 = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model_6 = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "\n",
        "\n",
        "\n",
        "predictions1=[]\n",
        "predictions2=[]\n",
        "predictions3=[]\n",
        "predictions4=[]\n",
        "predictions5=[]\n",
        "predictions6=[]\n",
        "\n",
        "\n",
        "\n",
        "k = 1\n",
        "\n",
        "for train_index, test_index in loocv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "\n",
        "    model_1.fit(X_train, y_train)\n",
        "    model_2.fit()\n",
        "    model_3.fit(X_train, y_train)\n",
        "    model_4.fit(X_train, y_train)\n",
        "    model_5.fit(X_train, y_train)\n",
        "    model_6.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "    y_pred_1 = model_1.predict(X_test)\n",
        "    y_pred_2 = model_2.predict(X_test)\n",
        "    y_pred_3 = model_3.predict(X_test)\n",
        "    y_pred_4 = model_4.predict(X_test)\n",
        "    y_pred_5 = model_5.predict(X_test)\n",
        "    y_pred_6 = model_6.predict(X_test)\n",
        "\n",
        "    y_pred_combined_1 = median_combination(y_pred_1, y_pred_2, y_pred_3)\n",
        "    y_pred_combined_2 = median_combination(y_pred_1, y_pred_2, y_pred_4)\n",
        "    y_pred_combined_3 = median_combination(y_pred_1, y_pred_2, y_pred_5)\n",
        "    y_pred_combined_4 = median_combination(y_pred_1, y_pred_2, y_pred_6)\n",
        "\n",
        "\n",
        "    combined_predictions_1.extend(y_pred_combined_1)\n",
        "    combined_predictions_2.extend(y_pred_combined_2)\n",
        "    combined_predictions_3.extend(y_pred_combined_3)\n",
        "    combined_predictions_4.extend(y_pred_combined_4)\n",
        "\n",
        "    actuals.extend(y_test)\n",
        "\n",
        "    predictions1.extend(y_pred_1)\n",
        "    predictions2.extend(y_pred_2)\n",
        "    predictions3.extend(y_pred_3)\n",
        "    predictions4.extend(y_pred_4)\n",
        "    predictions5.extend(y_pred_5)\n",
        "    predictions6.extend(y_pred_6)\n",
        "\n",
        "    k = k + 1\n",
        "\n",
        "ensemble_predictions = [combined_predictions_1, combined_predictions_2, combined_predictions_3, combined_predictions_4]\n",
        "individual_predictions = [predictions1, predictions2, predictions3, predictions4, predictions5, predictions6]\n",
        "\n",
        "ensemble_mae, ensemble_pred25, ensemble_mmre = calculate_metrics(actuals, ensemble_predictions)\n",
        "individual_mae, individual_pred25, individual_mmre = calculate_metrics(actuals, individual_predictions)\n",
        "\n",
        "bmmre = []\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions3]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions4]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions5]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions6]))\n",
        "\n",
        "ensemble_df, individual_df = display_results(ensemble_models, individual_models, ensemble_mae, ensemble_pred25, ensemble_mmre,individual_mae, individual_pred25,individual_mmre,bmmre)\n",
        "\n",
        "save_to_excel(file_name,  \"loocv-unscaled-median\", ensemble_df, individual_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnvLgWfNLRu4"
      },
      "source": [
        "**K-Fold - unscaled - median**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EARKIqZ1KvNM",
        "outputId": "006cd1fa-fea1-4400-e3a1-52f9e3655dcb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "combined_predictions_1=[]\n",
        "combined_predictions_2=[]\n",
        "combined_predictions_3=[]\n",
        "combined_predictions_4=[]\n",
        "\n",
        "model_1 = CBR()\n",
        "model_2 = COCOMO()\n",
        "model_3 = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, learning_rate_init=0.01, activation='relu', solver='adam', random_state=42)\n",
        "model_4 = KNeighborsRegressor(n_neighbors=5)\n",
        "model_5 = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model_6 = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "\n",
        "\n",
        "\n",
        "predictions1=[]\n",
        "predictions2=[]\n",
        "predictions3=[]\n",
        "predictions4=[]\n",
        "predictions5=[]\n",
        "predictions6=[]\n",
        "\n",
        "\n",
        "\n",
        "k = 1\n",
        "\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model_1.fit(X_train, y_train)\n",
        "    model_2.fit()\n",
        "    model_3.fit(X_train, y_train)\n",
        "    model_4.fit(X_train, y_train)\n",
        "    model_5.fit(X_train, y_train)\n",
        "    model_6.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_1 = model_1.predict(X_test)\n",
        "    y_pred_2 = model_2.predict(X_test)\n",
        "    y_pred_3 = model_3.predict(X_test)\n",
        "    y_pred_4 = model_4.predict(X_test)\n",
        "    y_pred_5 = model_5.predict(X_test)\n",
        "    y_pred_6 = model_6.predict(X_test)\n",
        "\n",
        "    y_pred_combined_1 = median_combination(y_pred_1, y_pred_2, y_pred_3)\n",
        "    y_pred_combined_2 = median_combination(y_pred_1, y_pred_2, y_pred_4)\n",
        "    y_pred_combined_3 = median_combination(y_pred_1, y_pred_2, y_pred_5)\n",
        "    y_pred_combined_4 = median_combination(y_pred_1, y_pred_2, y_pred_6)\n",
        "\n",
        "    combined_predictions_1.extend(y_pred_combined_1)\n",
        "    combined_predictions_2.extend(y_pred_combined_2)\n",
        "    combined_predictions_3.extend(y_pred_combined_3)\n",
        "    combined_predictions_4.extend(y_pred_combined_4)\n",
        "\n",
        "    actuals.extend(y_test)\n",
        "\n",
        "    predictions1.extend(y_pred_1)\n",
        "    predictions2.extend(y_pred_2)\n",
        "    predictions3.extend(y_pred_3)\n",
        "    predictions4.extend(y_pred_4)\n",
        "    predictions5.extend(y_pred_5)\n",
        "    predictions6.extend(y_pred_6)\n",
        "\n",
        "    k = k + 1\n",
        "\n",
        "ensemble_predictions = [combined_predictions_1, combined_predictions_2, combined_predictions_3, combined_predictions_4]\n",
        "individual_predictions = [predictions1, predictions2, predictions3, predictions4, predictions5, predictions6]\n",
        "\n",
        "ensemble_mae, ensemble_pred25, ensemble_mmre = calculate_metrics(actuals, ensemble_predictions)\n",
        "individual_mae, individual_pred25, individual_mmre = calculate_metrics(actuals, individual_predictions)\n",
        "\n",
        "bmmre = []\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions3]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions4]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions5]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions6]))\n",
        "\n",
        "ensemble_df, individual_df = display_results(ensemble_models, individual_models, ensemble_mae, ensemble_pred25, ensemble_mmre,individual_mae, individual_pred25,individual_mmre,bmmre)\n",
        "\n",
        "save_to_excel(file_name,\"kfold-unscaled-median\", ensemble_df, individual_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl6T-8DXNssA"
      },
      "source": [
        "**kfold - unscaled - linear combination**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1eWVohGNrh8",
        "outputId": "e76d013d-c01b-43ad-f6fa-05e562b8e4b4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "combined_predictions_1=[]\n",
        "combined_predictions_2=[]\n",
        "combined_predictions_3=[]\n",
        "combined_predictions_4=[]\n",
        "\n",
        "model_1 = CBR()\n",
        "model_2 = COCOMO()\n",
        "model_3 = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, learning_rate_init=0.01, activation='relu', solver='adam', random_state=42)\n",
        "model_4 = KNeighborsRegressor(n_neighbors=5)\n",
        "model_5 = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "model_6 = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predictions1=[]\n",
        "predictions2=[]\n",
        "predictions3=[]\n",
        "predictions4=[]\n",
        "predictions5=[]\n",
        "predictions6=[]\n",
        "\n",
        "\n",
        "\n",
        "k = 1\n",
        "\n",
        "for train_index, test_index in kfold.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model_1.fit(X_train, y_train)\n",
        "    model_2.fit()\n",
        "    model_3.fit(X_train, y_train)\n",
        "    model_4.fit(X_train, y_train)\n",
        "    model_5.fit(X_train, y_train)\n",
        "    model_6.fit(X_train, y_train)\n",
        "\n",
        "    y_pred_1 = model_1.predict(X_test)\n",
        "    y_pred_2 = model_2.predict(X_test)\n",
        "    y_pred_3 = model_3.predict(X_test)\n",
        "    y_pred_4 = model_4.predict(X_test)\n",
        "    y_pred_5 = model_5.predict(X_test)\n",
        "    y_pred_6 = model_6.predict(X_test)\n",
        "\n",
        "    y_pred_combined_1 = linear_combination(y_pred_1, y_pred_2, y_pred_3,[0.4,0.3,0.3])\n",
        "    y_pred_combined_2 = linear_combination(y_pred_1, y_pred_2, y_pred_4,[0.4,0.3,0.3])\n",
        "    y_pred_combined_3 = linear_combination(y_pred_1, y_pred_2, y_pred_5,[0.4,0.3,0.3])\n",
        "    y_pred_combined_4 = linear_combination(y_pred_1, y_pred_2, y_pred_6,[0.4,0.3,0.3])\n",
        "\n",
        "    combined_predictions_1.extend(y_pred_combined_1)\n",
        "    combined_predictions_2.extend(y_pred_combined_2)\n",
        "    combined_predictions_3.extend(y_pred_combined_3)\n",
        "    combined_predictions_4.extend(y_pred_combined_4)\n",
        "\n",
        "    actuals.extend(y_test)\n",
        "\n",
        "    predictions1.extend(y_pred_1)\n",
        "    predictions2.extend(y_pred_2)\n",
        "    predictions3.extend(y_pred_3)\n",
        "    predictions4.extend(y_pred_4)\n",
        "    predictions5.extend(y_pred_5)\n",
        "    predictions6.extend(y_pred_6)\n",
        "\n",
        "    k = k + 1\n",
        "\n",
        "\n",
        "\n",
        "ensemble_predictions = [combined_predictions_1, combined_predictions_2, combined_predictions_3, combined_predictions_4]\n",
        "individual_predictions = [predictions1, predictions2, predictions3, predictions4, predictions5, predictions6]\n",
        "\n",
        "ensemble_mae, ensemble_pred25, ensemble_mmre = calculate_metrics(actuals, ensemble_predictions)\n",
        "individual_mae, individual_pred25, individual_mmre = calculate_metrics(actuals, individual_predictions)\n",
        "\n",
        "bmmre = []\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions3]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions4]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions5]))\n",
        "bmmre.append(calculate_bmmre(actuals, [predictions1,predictions2,predictions6]))\n",
        "\n",
        "ensemble_df, individual_df = display_results(ensemble_models, individual_models, ensemble_mae, ensemble_pred25, ensemble_mmre,individual_mae, individual_pred25,individual_mmre,bmmre)\n",
        "\n",
        "save_to_excel(file_name,\"kfold-unscaled-linear\", ensemble_df, individual_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
